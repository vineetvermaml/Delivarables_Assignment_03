{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 3: Chart Image Classification cation using CNN"
      ],
      "metadata": {
        "id": "vpx2ILtX2Ihf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem statement: \n",
        "You have to develop a CNN-based classi\n",
        "cation architecture for clas-\n",
        "sifying a given chart image to one of \n",
        "ve chart classes, "
      ],
      "metadata": {
        "id": "z4ppHp8le_iT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1:\n",
        "Download the dataset from drive link given below.\n",
        "Dataset link\n",
        "Use the train and val images for training and validation in an appropriate ratio (e.g., 80% for\n",
        "training and 20 % for validating). The CSV \n",
        "le contains corresponding labels for the images."
      ],
      "metadata": {
        "id": "heS1XwjtwCrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all necessary Libraries\n",
        "import os\n",
        "from os.path  import join\n",
        "import struct\n",
        "from array import array\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "agaSMTpkfG_R"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataframe for the label dataframe\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Machine Learning Assignment03/Problem 03/charts/train_val.csv\")\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bpTowlZkbZU",
        "outputId": "83fed92b-3562-4953-9180-05cf8a0e92ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['image_index', 'type'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['type']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_c4M_cnxk5s",
        "outputId": "e7a94a69-12eb-4d75-bdbd-b29d6d4571af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      vbar_categorical\n",
              "1      vbar_categorical\n",
              "2      vbar_categorical\n",
              "3      vbar_categorical\n",
              "4      vbar_categorical\n",
              "             ...       \n",
              "995            dot_line\n",
              "996            dot_line\n",
              "997            dot_line\n",
              "998            dot_line\n",
              "999            dot_line\n",
              "Name: type, Length: 1000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map the categorical values to numerical codes\n",
        "type_to_code = {'line':0, 'dot_line':1, 'pie':2, 'hbar_categorical':3, 'vbar_categorical':4}\n",
        "df['type_code'] = df['type'].map(type_to_code)"
      ],
      "metadata": {
        "id": "lVIVV--UwNaV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verifying column values \n",
        "df['type_code']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqctHVVYxqMd",
        "outputId": "20374d5a-fd0f-4ab9-8a90-e6e804bb38c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      4\n",
              "1      4\n",
              "2      4\n",
              "3      4\n",
              "4      4\n",
              "      ..\n",
              "995    1\n",
              "996    1\n",
              "997    1\n",
              "998    1\n",
              "999    1\n",
              "Name: type_code, Length: 1000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting label dataframe to label list\n",
        "label = df['type_code'].values.tolist()"
      ],
      "metadata": {
        "id": "MFVk1skCkdxY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dir = '/content/drive/MyDrive/Machine Learning Assignment03/Problem 03/charts/train_val'\n",
        "filenames = os.listdir(label_dir)"
      ],
      "metadata": {
        "id": "FRKLm166miHj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_path_list = sorted(os.listdir(label_dir), key=lambda filename: int(filename.split('.')[0]))\n",
        "\n",
        "sorted_filenames = sorted(filenames, key=lambda filename: int(filename.split('.')[0]))"
      ],
      "metadata": {
        "id": "bqfJziJ-nCm7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_dir = '/content/drive/MyDrive/Machine Learning Assignment03/Problem 03/charts/train_val'"
      ],
      "metadata": {
        "id": "y6dy7EVcqf8s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_img_path = []\n",
        "for img_file in sorted_filenames:\n",
        "    img_path = os.path.join(src_dir, img_file)\n",
        "    full_img_path.append(img_path)"
      ],
      "metadata": {
        "id": "Lwr5fxhwqX0o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cRVEr6-rJul_"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for img_file, class_label in zip(full_img_path, label):\n",
        "    data.append((img_file, class_label))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI2UMx40e5-e",
        "outputId": "3289e1b6-22aa-4ce4-fa8c-c33c333c7dd8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1OUxYbMx5iG",
        "outputId": "f856831e-069e-4e89-f373-1843869a3c15"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Machine Learning Assignment03/Problem 03/charts/train_val/1.png',\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_ratio = 0.8\n",
        "# Shuffle the data\n",
        "random.shuffle(data)\n",
        "\n",
        "# Split the data into train and test sets (80:20 ratio)\n",
        "split_index = int(len(data) * split_ratio)\n",
        "train_data = data[:split_index]\n",
        "test_data = data[split_index:]\n",
        "\n",
        "random.shuffle(train_data)\n",
        "random.shuffle(test_data)"
      ],
      "metadata": {
        "id": "bHPDvLiZg8f5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total number of images: {len(data)}')\n",
        "print(f'Number of train images: {len(train_data)}')\n",
        "print(f'Number of test images: {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZWVEH2VhSGB",
        "outputId": "c58047c6-bd09-442f-d2db-553a31101c11"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images: 1000\n",
            "Number of train images: 800\n",
            "Number of test images: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the images and labels\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "# Set the image size\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "\n",
        "\n",
        "\n",
        "X_train = []\n",
        "Y_train = []\n",
        "for img_path, label in train_data:\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.resize(img, (img_height, img_width))\n",
        "  img = img / 255.0\n",
        "  X_train.append(img)\n",
        "  Y_train.append(label)\n",
        "\n",
        "X_test = []\n",
        "Y_test = []\n",
        "for img_path, label in test_data:\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.resize(img, (img_height, img_width))\n",
        "  img = img / 255.0\n",
        "  X_test.append(img)\n",
        "  Y_test.append(label)\n"
      ],
      "metadata": {
        "id": "o1VAAoXqhmcq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to numpy arrays\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "X_test = np.array(X_test)\n",
        "Y_test = np.array(Y_test)"
      ],
      "metadata": {
        "id": "Gkc-qArCjaRF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7l5hLJKuaj6",
        "outputId": "0a110fba-509f-49f1-ceaf-e396742979e9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200,)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YotVrH_Tuk87",
        "outputId": "adfd81b7-72f4-4732-d640-e6613ea39342"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 0, 2, 4, 2, 3, 2, 3, 2, 1, 1, 2, 4, 1, 3, 4, 3, 4, 4, 2, 3,\n",
              "       1, 3, 1, 3, 4, 4, 3, 2, 3, 0, 0, 1, 0, 4, 0, 4, 0, 2, 0, 3, 2, 2,\n",
              "       0, 2, 0, 2, 1, 3, 1, 2, 0, 3, 1, 4, 3, 2, 2, 1, 4, 2, 1, 1, 3, 1,\n",
              "       0, 4, 2, 2, 3, 3, 1, 3, 3, 1, 2, 4, 4, 4, 3, 0, 4, 1, 3, 1, 3, 3,\n",
              "       4, 1, 1, 0, 2, 2, 4, 2, 4, 0, 4, 1, 0, 1, 2, 3, 3, 2, 3, 2, 2, 2,\n",
              "       4, 3, 2, 2, 3, 0, 4, 4, 4, 2, 1, 4, 4, 3, 4, 0, 2, 1, 2, 1, 3, 2,\n",
              "       2, 4, 3, 2, 0, 4, 2, 2, 4, 4, 1, 0, 4, 4, 4, 2, 2, 2, 2, 2, 4, 3,\n",
              "       1, 2, 1, 2, 4, 2, 4, 3, 2, 3, 1, 2, 1, 3, 4, 4, 1, 1, 3, 0, 3, 4,\n",
              "       0, 2, 1, 4, 3, 1, 4, 3, 1, 0, 0, 1, 0, 2, 1, 0, 4, 2, 1, 4, 0, 4,\n",
              "       0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(Y_train))\n",
        "Y_train = np.eye(num_classes)[Y_train.astype('int32').flatten()]\n",
        "Y_test = np.eye(num_classes)[Y_test.astype('int32').flatten()]"
      ],
      "metadata": {
        "id": "MXsuCyx6u_iw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U7BZoKOyFot",
        "outputId": "6bc1b1ab-d4ef-4d16-e7e6-71072665d30e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShmhG60oyIa4",
        "outputId": "3decba33-f0b6-4732-9af1-6f9e59e0b3b1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 128, 128, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2:\n",
        "Implement a two-layer Convolutional Neural Network, and calculate accuracy,\n",
        "and loss and plot the obtained loss. Brie\n",
        "y write your observation and submit your code so\n",
        "that we can4 evaluate your implementation at our end."
      ],
      "metadata": {
        "id": "PAI1yFr3vAZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TWO Layered Convolutional Network"
      ],
      "metadata": {
        "id": "88NbgY7d1CoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Define the input shape of the images\n",
        "input_shape = (128, 128, 3)\n",
        "\n",
        "# Define the number of output classes\n",
        "num_classes = 5\n",
        "\n",
        "# Define the model architecture [TWO Layered Convolutional Network]\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model Summary\n",
        "print(model.summary())\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "model.fit(X_train, Y_train,  epochs=epochs)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd_Mge6f0_AE",
        "outputId": "075fe4b4-bd1b-47a5-e9db-0ee0b93d34fa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 57600)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                3686464   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,706,181\n",
            "Trainable params: 3,706,181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 24s 910ms/step - loss: 1.9410 - accuracy: 0.3988\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 20s 779ms/step - loss: 0.4514 - accuracy: 0.8062\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 21s 856ms/step - loss: 0.2628 - accuracy: 0.8838\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 21s 850ms/step - loss: 0.1806 - accuracy: 0.9275\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 21s 839ms/step - loss: 0.1229 - accuracy: 0.9600\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 20s 789ms/step - loss: 0.0814 - accuracy: 0.9800\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 23s 906ms/step - loss: 0.0458 - accuracy: 0.9912\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 19s 753ms/step - loss: 0.0250 - accuracy: 0.9925\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 19s 762ms/step - loss: 0.0187 - accuracy: 0.9975\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 21s 830ms/step - loss: 0.0124 - accuracy: 1.0000\n",
            "7/7 [==============================] - 1s 158ms/step - loss: 0.0789 - accuracy: 0.9550\n",
            "Test accuracy: 0.9549999833106995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17ZzjmTxvypm",
        "outputId": "9487b744-3ec6-4cc5-a0ef-0448f08c5c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 167ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicted class value probability for one image\n",
        "prediction[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mlNANW3v25K",
        "outputId": "d8c5528c-d67f-4e23-8abc-86eb080d8ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.3861574e-11, 1.6932214e-10, 3.4869031e-11, 9.9999994e-01,\n",
              "       4.7809357e-11], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# truth value\n",
        "Y_test[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DYfmBjWxbHR",
        "outputId": "9c839d36-5bc5-47d4-9409-c7c89867dea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing above prediction and truth value/lable we can see our model is working fine [ Test accuracy: 0.9800000190734863 ]"
      ],
      "metadata": {
        "id": "OYXAFncFx2BG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi layered Convolutional Network . \n",
        "\n",
        "Multi Layered CNN were performing even better than Two layered CNN ."
      ],
      "metadata": {
        "id": "2Jq3Vwc-1qwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "model.fit(X_train, Y_train,  epochs=epochs)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNCgxP08yWrh",
        "outputId": "5398ce5f-e363-471c-bd64-81f8bf4b092b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 63, 63, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               3211392   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,305,285\n",
            "Trainable params: 3,305,285\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.2591 - accuracy: 0.4613\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.4578 - accuracy: 0.7875\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.3378 - accuracy: 0.8600\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.3049 - accuracy: 0.8712\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 28s 1s/step - loss: 0.3063 - accuracy: 0.8725\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 29s 1s/step - loss: 0.1882 - accuracy: 0.9287\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 29s 1s/step - loss: 0.1059 - accuracy: 0.9700\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 28s 1s/step - loss: 0.1015 - accuracy: 0.9712\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 29s 1s/step - loss: 0.0659 - accuracy: 0.9825\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 29s 1s/step - loss: 0.0402 - accuracy: 0.9875\n",
            "7/7 [==============================] - 2s 230ms/step - loss: 0.0539 - accuracy: 0.9900\n",
            "Test accuracy: 0.9900000095367432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3:\n",
        "Finetune a pretrained network (e.g., AlexNet) for this task and report the results. \n",
        "### Using Pre-trained model VGG16"
      ],
      "metadata": {
        "id": "VARjcOsduWLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.applications import VGG16\n",
        "\n",
        "# Define the number of output classes\n",
        "num_classes = 5\n",
        "\n",
        "# Load the pretrained VGG16 model\n",
        "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# Freeze all the layers in the pretrained model\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model that includes the pretrained model and a new output layer\n",
        "model = Sequential([\n",
        "    vgg16,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with categorical cross-entropy loss and Adam optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print a summary of the model architecture\n",
        "print(model.summary())\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "model.fit(X_train, Y_train,  epochs=epochs)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print('Test accuracy:', accuracy)\n"
      ],
      "metadata": {
        "id": "372CNu1j4utV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c80b14-3d4b-4f81-aa01-1d0a3656b85a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               2097408   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,813,381\n",
            "Trainable params: 2,098,693\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 168s 7s/step - loss: 0.3493 - accuracy: 0.8988\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 167s 7s/step - loss: 0.0074 - accuracy: 0.9975\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 165s 6s/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 165s 7s/step - loss: 3.8407e-04 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 160s 6s/step - loss: 2.5682e-04 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 165s 7s/step - loss: 1.9026e-04 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 160s 6s/step - loss: 1.5978e-04 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 165s 7s/step - loss: 1.2605e-04 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 165s 7s/step - loss: 1.0573e-04 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 161s 6s/step - loss: 9.4110e-05 - accuracy: 1.0000\n",
            "7/7 [==============================] - 40s 6s/step - loss: 0.0041 - accuracy: 0.9950\n",
            "Test accuracy: 0.9950000047683716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "esYJ9OjcC8b9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}